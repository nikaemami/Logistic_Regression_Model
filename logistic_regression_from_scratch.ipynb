{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import csv\n",
    "import seaborn as sns\n",
    "import math\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"/Users/Nika/Desktop/Stress-Lysis.csv\")\n",
    "df = pd.DataFrame(data, columns=[\"Humidity\", \"Temperature\", \"Step_count\", \"Stress_Level\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I split the data into training and testing sets by choosing random samplses. (80 percent for train and 20 percent for test):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = np.random.rand(len(df)) <= 0.8\n",
    "training_data = df[mask]\n",
    "testing_data = df[~mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I define several functions in the code.\n",
    "First, I implement the **sigmoid** function as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    sigmoid = 1 / (1 + np.exp(-x))\n",
    "    return sigmoid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I implement a function for calculating the **weights** in each iteration.\n",
    "\n",
    "\n",
    "I define a certian **learning rate** and **number of iterations**, and by having the temperature and humidity of the training data as the features, along with using the **gradient descent** method, I compute the weights by using the corresponding mathematical expressions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def w_calc(data, label):\n",
    "    eta = 0.00000001 \n",
    "    n_iterations = 200\n",
    "\n",
    "    n = len(data)\n",
    "    w = np.random.randn(2,1)\n",
    "    w_transpose = w.transpose()\n",
    "\n",
    "    temperature = data['Temperature'].values.tolist()\n",
    "    humidity = data['Humidity'].values.tolist()\n",
    "\n",
    "    features = np.ones((len(temperature),2))\n",
    "    for i in range(len(temperature)):\n",
    "        features[i][0] = temperature[i]\n",
    "        features[i][1] = humidity[i]\n",
    "\n",
    "    label_list = data['Stress_Level'].values.tolist()\n",
    "    yi = []\n",
    "    for i in range(len(label_list)):\n",
    "        if(label_list[i] == label):\n",
    "            yi.append(1)\n",
    "        else:\n",
    "            yi.append(0)\n",
    "\n",
    "    x = np.ones((1,2))\n",
    "    for j in range(n_iterations):\n",
    "        gradients = 0\n",
    "        for i in range(len(temperature)):\n",
    "            x = features[i]\n",
    "            x = np.reshape(x,(len(x),1))\n",
    "            multiplication = np.dot(w_transpose,x)\n",
    "            gradients+=x * (yi[i]-sigmoid(multiplication))\n",
    "        w = w + (eta * gradients)\n",
    "    \n",
    "    return w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I define the final function as the classifier:\n",
    "\n",
    "\n",
    "I compute w for each class and by having the temprature and humidity of the testing data, I estimate a label for each of the testing samples. I use **one vs all** logistic regression by comparing the probability of each class, and then choose the class that has **max probability** as the estimated class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifier(training_data, test_data):\n",
    "    w_high = w_calc(training_data, 'high')\n",
    "    w_high = w_high.transpose()\n",
    "    w_mid = w_calc(training_data, 'mid')\n",
    "    w_mid = w_mid.transpose()\n",
    "    w_low = w_calc(training_data, 'low')\n",
    "    w_low = w_low.transpose()\n",
    "\n",
    "    temperature = test_data['Temperature'].values.tolist()\n",
    "    humidity = test_data['Humidity'].values.tolist()\n",
    "\n",
    "    features = np.ones((len(temperature),2))\n",
    "    label = []\n",
    "    for i in range(len(temperature)):\n",
    "        features[i][0] = temperature[i]\n",
    "        features[i][1] = humidity[i]\n",
    "\n",
    "        x = features[i]\n",
    "        x = np.reshape(x,(len(x),1))\n",
    "\n",
    "        probability_high = sigmoid(np.dot(w_high,x))\n",
    "        probability_mid = sigmoid(np.dot(w_mid,x))\n",
    "        probability_low = sigmoid(np.dot(w_low,x))\n",
    "\n",
    "        if ((probability_high >= probability_low) and (probability_high >= probability_mid)):\n",
    "            label.append('high')\n",
    "        elif ((probability_low >= probability_high) and (probability_low >= probability_mid)):\n",
    "            label.append('low')\n",
    "        else:\n",
    "            label.append('mid')\n",
    "\n",
    "    return label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computing the 3x3 **confusion matrix** as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix =  [[130, 0, 0], [156, 0, 0], [103, 0, 0]]\n",
      "accuracy =  0.3341902313624679\n"
     ]
    }
   ],
   "source": [
    "classification = classifier(training_data, testing_data)\n",
    "T1=F12=F21=T2=T3=F13=F31=F32=F23=0\n",
    "test_list = testing_data['Stress_Level'].values.tolist()\n",
    "\n",
    "for i in range (len(test_list)):\n",
    "    if (test_list[i] == \"high\" and classification[i] == \"high\"):\n",
    "        T1+=1\n",
    "    elif(test_list[i] == \"high\" and classification[i] == \"mid\"):\n",
    "        F12+=1\n",
    "    elif(test_list[i] == \"high\" and classification[i] == \"low\"):\n",
    "        F13+=1\n",
    "    if (test_list[i] == \"mid\" and classification[i] == \"mid\"):\n",
    "        T2+=1\n",
    "    elif(test_list[i] == \"mid\" and classification[i] == \"low\"):\n",
    "        F23+=1\n",
    "    elif(test_list[i] == \"mid\" and classification[i] == \"high\"):\n",
    "        F21+=1\n",
    "    if (test_list[i] == \"low\" and classification[i] == \"low\"):\n",
    "        T3+=1\n",
    "    elif(test_list[i] == \"low\" and classification[i] == \"mid\"):\n",
    "        F32+=1\n",
    "    elif(test_list[i] == \"low\" and classification[i] == \"high\"):\n",
    "        F31+=1\n",
    "\n",
    "\n",
    "Confusion_Matrix=[[T1,F12,F13],[F21,T2,F23],[F31,F32,T3]]\n",
    "print(\"Confusion Matrix = \", Confusion_Matrix)\n",
    "accuracy = (T1+T2+T3)/(T1+T2+T3+F21+F12+F23+F32+F13+F31)\n",
    "print(\"accuracy = \", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By computing accuracy and recall, we can compute the **F1 Score**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score = 0.5009633911368016\n"
     ]
    }
   ],
   "source": [
    "recall = T1 / (F12 + F13 + T1)\n",
    "print(\"F1 score =\", 2/((1/recall) + (1/accuracy)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **Jaccard Score**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jaccard score =  0.3341902313624679\n"
     ]
    }
   ],
   "source": [
    "jaccard = T1/(T1+F21+F12+F13+F31)\n",
    "print(\"jaccard score = \",jaccard)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "eeab3e71adb6dbd0e75fb9a8c9bdb5e7c4aba7cf3fd60c4dcf30c1777b01516d"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
